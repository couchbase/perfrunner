[test_case]
test = perfrunner.tests.n1ql.N1QLThroughputTest
title = Q6, Order By Limit Query, 20M docs, 14.4KGops, 3.6KSops, GSI, request_plus
summary = Order By Limit Query, 14.4KGops, 3.6KSops
larger_is_better = true

[cluster]
mem_quota = 20480
index_mem_quota = 100000
initial_nodes = 6
num_buckets = 1

[secondary]
indexer.settings.storage_mode = forestdb
indexer.settings.compaction.min_size = 1048576
indexer.settings.persisted_snapshot.interval = 3000
indexer.settings.wal_size = 40960
indexer.settings.maxVbQueueLength = 10000
indexer.settings.max_cpu_percent = 2400
indexer.settings.scan_timeout = 0
indexer.settings.gc_percent = 200

[load]
items = 20000000
size = 1024
workers = 80
doc_gen = reverse_lookup

[n1ql]
indexes =
    by_capped_small::CREATE INDEX {name} ON `{bucket}` (capped_small) using gsi;

[access]
creates = 0
reads = 80
updates = 20
deletes = 0
throughput = 18000
items = 20000000
workers = 20
time = 1200
n1ql_queries = order-by-limit-query
n1ql_throughput = 1000000
n1ql_workers = 720

[n1ql-order-by-limit-query]
prepared = order_by_limit_query
statement = SELECT name AS _name, street AS _street FROM `bucket-1` WHERE capped_small=$1 ORDER BY name LIMIT 100;
scan_consistency = request_plus
args = ["{capped_small}"]
